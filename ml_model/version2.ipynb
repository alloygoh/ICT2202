{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54e8bb9-988c-4e18-83b6-39db0319c057",
   "metadata": {},
   "source": [
    "# Create CSV of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86e39a3-3038-4a05-8371-fc3e153d3ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "directories = [\"data/benign\", \"data/malicious\", \"data/mixed\"]\n",
    "output_file = \"labels.csv\"\n",
    "\n",
    "with open(output_file, 'a', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow([\"filename\", \"label\"])\n",
    "for d in directories:\n",
    "    label = os.path.basename(d)\n",
    "    label = \"malicious\" if label == \"mixed\" else label\n",
    "    for root, _, files in os.walk(d):\n",
    "        for file in files:\n",
    "            with open(output_file, 'a', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile, quoting=csv.QUOTE_MINIMAL)\n",
    "                writer.writerow([f\"{root}/{file}\", label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63918371-4a21-4f07-9489-86f1caae08a0",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1cbf7f-173f-420d-bc79-b342fc4c4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "labels = pd.read_csv('labels.csv')\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d853f13-fd5b-4aeb-86b5-acb896fbdd31",
   "metadata": {},
   "source": [
    "## URL or IP\n",
    "- Boolean\n",
    "- Checks for the usage of URL or IP within the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb7fb9-8301-482f-8870-91ecc874f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def has_url_or_ip(content: str) -> bool:\n",
    "    ip_addr_regex = r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\"\n",
    "    url_regex = r\"(http.*?)['\\\"]?\"\n",
    "    has_ip = bool(re.search(ip_addr_regex, content))\n",
    "    has_url = bool(re.search(url_regex, content))\n",
    "    return int(has_ip or has_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e886c-3c36-43f3-ada3-049b1845d231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character_length_info(content: str):\n",
    "    \"\"\"\n",
    "    Returns number of strings, max length of strings, and average length\n",
    "    \"\"\"\n",
    "    # Get all strings\n",
    "    import re\n",
    "    regex = r\"(['\\\"])(.*?)\\1\"\n",
    "    matches = re.findall(regex, content)\n",
    "    if not matches:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    count, sum_length, max_length = 0, 0, 0\n",
    "    for match in matches:\n",
    "        string = match[1]\n",
    "        string_length = len(string)\n",
    "\n",
    "        count += 1\n",
    "        sum_length += string_length\n",
    "    \n",
    "        if string_length > max_length:\n",
    "            max_length = string_length\n",
    "\n",
    "    return (count, max_length, sum_length/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87c33f-198f-493f-bfa6-3908877d6cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_character_occurences(content: str, top: int=5):\n",
    "    content = content.replace(' ', '')\n",
    "    return [x[0] for x in collections.Counter(content).most_common(top)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d29f4-20b5-4272-9a1b-05e7de8a1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab328e-f26f-4169-9729-bb7c54a4c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "\n",
    "def get_manual_features(row):\n",
    "    with open(row[\"filename\"], encoding=\"utf-8\") as f:\n",
    "        content = f.read().lower()\n",
    "        content = re.sub(r\"[\\s]+\", \" \", content)\n",
    "        row[\"str_count\"], row[\"str_max\"], row[\"str_avg\"] = get_character_length_info(content)\n",
    "        row[\"has_url_or_ip\"] = has_url_or_ip(content)\n",
    "        row = pd.concat([row, pd.Series(get_top_character_occurences(content), index=[f\"top{i}\" for i in range(5)])])\n",
    "        return row\n",
    "\n",
    "labels = labels.apply(get_manual_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a940d69-94c3-479b-a6e4-3eb3cb8af96d",
   "metadata": {},
   "source": [
    "# Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a2832f-3df4-4e73-9410-f37bdf476183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf8bee-8b33-4917-96c3-9ae79a91ac2f",
   "metadata": {},
   "source": [
    "# FastText Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc80cbee",
   "metadata": {},
   "source": [
    "Training the fasttext model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7487e6-5a57-4326-9210-708567ea3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "        \n",
    "def build_fasttext_vocab(filename, corpus_filename):\n",
    "    with open(filename, encoding=\"utf-8\") as f:\n",
    "        content = f.read().lower()\n",
    "        content = re.sub(\"[1-9]\", \"*\", content)\n",
    "        content = re.sub(\"[^a-zA-Z* $]\", \" \", content)\n",
    "        content = re.sub(r\"[\\s]+\", \" \", content)\n",
    "        content = content.strip()\n",
    "\n",
    "    with open(f'processed/{filename}', \"w\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "    with open(f'{corpus_filename}.txt', \"a\") as f:\n",
    "        f.write(content + \"\\n\")\n",
    "\n",
    "train[\"filename\"].apply(lambda x: build_fasttext_vocab(x, \"train\"))\n",
    "test[\"filename\"].apply(lambda x: build_fasttext_vocab(x, \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82791844-d5c0-4841-aa0a-67adb22d9666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "words = [a.split() for a in open(\"train.txt\")]\n",
    "model = FastText()\n",
    "model.build_vocab(corpus_iterable=words)\n",
    "\n",
    "model_name = \"model.bin\"\n",
    "if os.path.exists(model_name):\n",
    "    model = FastText.load(\"model.bin\")\n",
    "else:\n",
    "    model.train(corpus_iterable=words, total_examples=len(words), epochs=10)  # train\n",
    "    model.save(\"model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8654e6f-74d7-4b60-8cab-f978768183b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "counter = 0\n",
    "def build_doc_embedding(row):\n",
    "    filename = row[\"filename\"]\n",
    "    with open(f\"processed/{filename}\") as f:\n",
    "        words = f.read().split()\n",
    "        num_features = 100\n",
    "        feature_vec = np.zeros((num_features,),dtype=\"float32\")  # pre-initialize (for speed)\n",
    "        for word in words:\n",
    "            feature_vec = np.add(feature_vec, model.wv[word])\n",
    "        global counter\n",
    "        print(counter, end='\\r')\n",
    "        counter += 1\n",
    "        feature_vec = np.divide(feature_vec, len(words))\n",
    "        return pd.concat([row, pd.Series(feature_vec, index=list(map(str, range(num_features))))])\n",
    "\n",
    "train = train.apply(build_doc_embedding, axis=1)\n",
    "test = test.apply(build_doc_embedding, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8d6de-e6e0-4c83-b8e1-37f830af7ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"filename\", \"label\"])\n",
    "y_train = train[\"label\"]\n",
    "X_test = test.drop(columns=[\"filename\", \"label\"])\n",
    "y_test = test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c283e03-3e0a-4a68-a027-0b86f229ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a49221-e781-4661-84f1-e0353cff1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "transformed = enc.fit_transform(X_train[[f\"top{i}\" for i in range(5)]])\n",
    "transformed_test = enc.transform(X_test[[f\"top{i}\" for i in range(5)]])\n",
    "X_train = X_train.join(pd.DataFrame(transformed.toarray(), columns=enc.get_feature_names_out())).drop(columns=[f\"top{i}\" for i in range(5)]).fillna(0)\n",
    "X_test = X_test.join(pd.DataFrame(transformed_test.toarray(), columns=enc.get_feature_names_out())).drop(columns=[f\"top{i}\" for i in range(5)]).fillna(0)\n",
    "import pickle\n",
    "with open(\"enc.bin\", \"wb\") as f:\n",
    "    pickle.dump(enc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0360801-f299-4f76-a152-d49e24972ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# clf = xgb.XGBClassifier()\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3221a-5c41-4424-a1d6-e0a1d566042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = clf.predict(X_test) \n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529ba901-1414-4800-8103-3e34db6f1bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"rf.bin\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "010d29f4aa5778a4dbdadd118c506844a5d5e5022a99655059752e101e034f11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
