{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b12537e-de93-4ab1-80c7-37eeebcd5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa95f20",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "- Replace IP addresses with \"ip_addr\"\n",
    "- Replace url with \"url\"\n",
    "- Lowercase everything\n",
    "- Split by delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf0b1ab-e79d-4362-aba3-53574bfbadcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = \"data/malicious\"\n",
    "\n",
    "subnet_regex = r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}/\\d{1,3}\"\n",
    "ip_addr_regex = r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\"\n",
    "url_regex = r\"(http.*?)['\\\"]\"\n",
    "output_directory=\"processed\"\n",
    "for root, subdir, files in os.walk(dirname):\n",
    "    for file in files:\n",
    "        content = None\n",
    "        with open(f'{root}/{file}', encoding=\"mbcs\") as f:\n",
    "            content = f.read()\n",
    "            content = re.sub(ip_addr_regex, \"ip_addr\", content)\n",
    "            content = re.sub(url_regex, \"url\", content)\n",
    "            content = content.lower()\n",
    "            content = re.split(r\"[;\\[\\s\\]{}\\(\\)\\+\\.\\&\\\"\\'\\,\\:]+\", content)\n",
    "            \n",
    "        with open(f'data/processed/malicious/{file}', \"w\", encoding=\"mbcs\") as f:\n",
    "            f.write(\"\\n\".join([c for c in content if c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff079f06-24dc-4c64-8125-5e0139bc6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subnet_regex = r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}/\\d{1,3}\"\n",
    "# with open(f'data/1023.ps1') as f:\n",
    "#     content = f.read()\n",
    "#     matches = re.sub(subnet_regex, \"subnet\", content)\n",
    "#     if matches:\n",
    "#         print(file)\n",
    "#         print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a032fa3b-b887-49ca-8be5-571a8498b1d1",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "- Vector of top N most frequent words\n",
    "- word2vec feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3bc836a-f982-4c08-a40c-0ff134859583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/processed/malicious/1.ps1', 'data/processed/malicious/10.ps1', 'data/processed/malicious/100.ps1', 'data/processed/malicious/1000.ps1', 'data/processed/malicious/1001.ps1']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "processed_directory = \"data/processed/malicious\"\n",
    "\n",
    "list_of_files = []\n",
    "for root, subdir, files in os.walk(processed_directory):\n",
    "    for file in files:\n",
    "        list_of_files.append(f'{root}/{file}')\n",
    "print(list_of_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cc7e83c-7c53-4cd9-9ad7-ba7895bc6d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(input=\"filename\", decode_error=\"ignore\")\n",
    "out = vectorizer.fit_transform(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f6ba938-3dbf-4b2b-9cd9-01c719876094",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'csr_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m output \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mcollections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCounter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\df_ps_classifier\\lib\\collections\\__init__.py:577\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;124;03m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03mof elements to their counts.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m \n\u001b[0;32m    575\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(iterable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\df_ps_classifier\\lib\\collections\\__init__.py:670\u001b[0m, in \u001b[0;36mCounter.update\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate(iterable)\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 670\u001b[0m         \u001b[43m_count_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds:\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'csr_matrix'"
     ]
    }
   ],
   "source": [
    "output = vectorizer.get_feature_names_out()\n",
    "import collections\n",
    "for row in out:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47833521-4d52-489c-a5ca-76c78edc783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 00:11:33,597 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc10,s0.001,t3>', 'datetime': '2022-10-17T00:11:33.597536', 'gensim': '4.2.0', 'python': '3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:29:51) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2022-10-17 00:11:33,599 : INFO : collecting all words and their counts\n",
      "2022-10-17 00:11:33,601 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2022-10-17 00:11:34,986 : INFO : collected 144978 word types and 4202 unique tags from a corpus of 4202 examples and 2938062 words\n",
      "2022-10-17 00:11:34,987 : INFO : Creating a fresh vocabulary\n",
      "2022-10-17 00:11:35,066 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 4527 unique words (3.12% of original 144978, drops 140451)', 'datetime': '2022-10-17T00:11:35.066800', 'gensim': '4.2.0', 'python': '3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:29:51) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-10-17 00:11:35,067 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 2744446 word corpus (93.41% of original 2938062, drops 193616)', 'datetime': '2022-10-17T00:11:35.067800', 'gensim': '4.2.0', 'python': '3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:29:51) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-10-17 00:11:35,102 : INFO : deleting the raw counts dictionary of 144978 items\n",
      "2022-10-17 00:11:35,109 : INFO : sample=0.001 downsamples 63 most-common words\n",
      "2022-10-17 00:11:35,110 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2036381.0465899603 word corpus (74.2%% of prior 2744446)', 'datetime': '2022-10-17T00:11:35.110339', 'gensim': '4.2.0', 'python': '3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:29:51) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-10-17 00:11:35,154 : INFO : estimated required memory for 4527 words and 50 dimensions: 5755100 bytes\n",
      "2022-10-17 00:11:35,155 : INFO : resetting layer weights\n",
      "2022-10-17 00:11:35,164 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 4527 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-10-17T00:11:35.164076', 'gensim': '4.2.0', 'python': '3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:29:51) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-10-17 00:11:36,171 : INFO : EPOCH 0 - PROGRESS: at 73.37% examples, 594518 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:11:37,102 : INFO : EPOCH 0: training on 2938062 raw words (1147156 effective words) took 1.9s, 593685 effective words/s\n",
      "2022-10-17 00:11:38,108 : INFO : EPOCH 1 - PROGRESS: at 80.13% examples, 654783 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:11:38,917 : INFO : EPOCH 1: training on 2938062 raw words (1147602 effective words) took 1.8s, 634077 effective words/s\n",
      "2022-10-17 00:11:39,920 : INFO : EPOCH 2 - PROGRESS: at 74.49% examples, 603725 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:11:40,780 : INFO : EPOCH 2: training on 2938062 raw words (1147682 effective words) took 1.9s, 616863 effective words/s\n",
      "2022-10-17 00:11:41,792 : INFO : EPOCH 3 - PROGRESS: at 82.27% examples, 667832 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:11:42,550 : INFO : EPOCH 3: training on 2938062 raw words (1147619 effective words) took 1.8s, 649639 effective words/s\n",
      "2022-10-17 00:11:43,562 : INFO : EPOCH 4 - PROGRESS: at 82.27% examples, 667564 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:11:44,312 : INFO : EPOCH 4: training on 2938062 raw words (1148273 effective words) took 1.8s, 653038 effective words/s\n",
      "2022-10-17 00:11:45,326 : INFO : EPOCH 5 - PROGRESS: at 81.18% examples, 656957 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:11:46,090 : INFO : EPOCH 5: training on 2938062 raw words (1147539 effective words) took 1.8s, 646413 effective words/s\n",
      "2022-10-17 00:11:47,095 : INFO : EPOCH 6 - PROGRESS: at 78.18% examples, 637787 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:11:47,886 : INFO : EPOCH 6: training on 2938062 raw words (1147457 effective words) took 1.8s, 640377 effective words/s\n",
      "2022-10-17 00:11:48,891 : INFO : EPOCH 7 - PROGRESS: at 82.27% examples, 672096 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:11:49,636 : INFO : EPOCH 7: training on 2938062 raw words (1147635 effective words) took 1.7s, 657106 effective words/s\n",
      "2022-10-17 00:11:50,652 : INFO : EPOCH 8 - PROGRESS: at 81.18% examples, 655953 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:11:51,401 : INFO : EPOCH 8: training on 2938062 raw words (1147412 effective words) took 1.8s, 651234 effective words/s\n",
      "2022-10-17 00:11:52,408 : INFO : EPOCH 9 - PROGRESS: at 81.18% examples, 662251 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:11:53,185 : INFO : EPOCH 9: training on 2938062 raw words (1147774 effective words) took 1.8s, 644948 effective words/s\n",
      "2022-10-17 00:11:54,194 : INFO : EPOCH 10 - PROGRESS: at 73.37% examples, 590639 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:11:55,125 : INFO : EPOCH 10: training on 2938062 raw words (1147441 effective words) took 1.9s, 592258 effective words/s\n",
      "2022-10-17 00:11:56,143 : INFO : EPOCH 11 - PROGRESS: at 74.49% examples, 595222 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:11:57,112 : INFO : EPOCH 11: training on 2938062 raw words (1147613 effective words) took 2.0s, 578644 effective words/s\n",
      "2022-10-17 00:11:58,119 : INFO : EPOCH 12 - PROGRESS: at 77.39% examples, 627130 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:11:58,985 : INFO : EPOCH 12: training on 2938062 raw words (1147901 effective words) took 1.9s, 613820 effective words/s\n",
      "2022-10-17 00:11:59,989 : INFO : EPOCH 13 - PROGRESS: at 75.37% examples, 612570 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:00,917 : INFO : EPOCH 13: training on 2938062 raw words (1147506 effective words) took 1.9s, 595031 effective words/s\n",
      "2022-10-17 00:12:01,922 : INFO : EPOCH 14 - PROGRESS: at 70.37% examples, 568197 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:02,878 : INFO : EPOCH 14: training on 2938062 raw words (1147918 effective words) took 2.0s, 586541 effective words/s\n",
      "2022-10-17 00:12:03,885 : INFO : EPOCH 15 - PROGRESS: at 62.49% examples, 497025 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:04,893 : INFO : EPOCH 15 - PROGRESS: at 98.79% examples, 500798 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:05,063 : INFO : EPOCH 15: training on 2938062 raw words (1147919 effective words) took 2.2s, 525995 effective words/s\n",
      "2022-10-17 00:12:06,068 : INFO : EPOCH 16 - PROGRESS: at 66.33% examples, 533948 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:07,087 : INFO : EPOCH 16 - PROGRESS: at 98.81% examples, 503218 words/s, in_qsize 0, out_qsize 1\n",
      "2022-10-17 00:12:07,205 : INFO : EPOCH 16: training on 2938062 raw words (1147474 effective words) took 2.1s, 536745 effective words/s\n",
      "2022-10-17 00:12:08,212 : INFO : EPOCH 17 - PROGRESS: at 69.40% examples, 557734 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:09,224 : INFO : EPOCH 17 - PROGRESS: at 99.24% examples, 526943 words/s, in_qsize 2, out_qsize 0\n",
      "2022-10-17 00:12:09,295 : INFO : EPOCH 17: training on 2938062 raw words (1147419 effective words) took 2.1s, 550000 effective words/s\n",
      "2022-10-17 00:12:10,305 : INFO : EPOCH 18 - PROGRESS: at 52.24% examples, 409964 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:11,311 : INFO : EPOCH 18 - PROGRESS: at 92.41% examples, 373178 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:12,316 : INFO : EPOCH 18 - PROGRESS: at 99.26% examples, 355286 words/s, in_qsize 2, out_qsize 0\n",
      "2022-10-17 00:12:12,373 : INFO : EPOCH 18: training on 2938062 raw words (1147533 effective words) took 3.1s, 373080 effective words/s\n",
      "2022-10-17 00:12:13,399 : INFO : EPOCH 19 - PROGRESS: at 38.67% examples, 303090 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:14,415 : INFO : EPOCH 19 - PROGRESS: at 80.13% examples, 321753 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:15,424 : INFO : EPOCH 19 - PROGRESS: at 98.88% examples, 337000 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:15,556 : INFO : EPOCH 19: training on 2938062 raw words (1147766 effective words) took 3.2s, 360947 effective words/s\n",
      "2022-10-17 00:12:16,575 : INFO : EPOCH 20 - PROGRESS: at 70.37% examples, 560823 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:17,632 : INFO : EPOCH 20 - PROGRESS: at 98.02% examples, 459245 words/s, in_qsize 0, out_qsize 1\n",
      "2022-10-17 00:12:18,080 : INFO : EPOCH 20: training on 2938062 raw words (1147751 effective words) took 2.5s, 455619 effective words/s\n",
      "2022-10-17 00:12:19,090 : INFO : EPOCH 21 - PROGRESS: at 71.18% examples, 573387 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:20,036 : INFO : EPOCH 21: training on 2938062 raw words (1147921 effective words) took 2.0s, 587746 effective words/s\n",
      "2022-10-17 00:12:21,045 : INFO : EPOCH 22 - PROGRESS: at 73.37% examples, 591389 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:21,992 : INFO : EPOCH 22: training on 2938062 raw words (1147683 effective words) took 2.0s, 587481 effective words/s\n",
      "2022-10-17 00:12:23,005 : INFO : EPOCH 23 - PROGRESS: at 75.37% examples, 606273 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:23,905 : INFO : EPOCH 23: training on 2938062 raw words (1147475 effective words) took 1.9s, 601298 effective words/s\n",
      "2022-10-17 00:12:24,910 : INFO : EPOCH 24 - PROGRESS: at 74.49% examples, 602322 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:25,807 : INFO : EPOCH 24: training on 2938062 raw words (1147871 effective words) took 1.9s, 604198 effective words/s\n",
      "2022-10-17 00:12:26,820 : INFO : EPOCH 25 - PROGRESS: at 75.37% examples, 606502 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:27,789 : INFO : EPOCH 25: training on 2938062 raw words (1147707 effective words) took 2.0s, 579857 effective words/s\n",
      "2022-10-17 00:12:28,808 : INFO : EPOCH 26 - PROGRESS: at 74.49% examples, 595094 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:29,713 : INFO : EPOCH 26: training on 2938062 raw words (1147213 effective words) took 1.9s, 597483 effective words/s\n",
      "2022-10-17 00:12:30,729 : INFO : EPOCH 27 - PROGRESS: at 74.49% examples, 596819 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:31,625 : INFO : EPOCH 27: training on 2938062 raw words (1147669 effective words) took 1.9s, 601243 effective words/s\n",
      "2022-10-17 00:12:32,635 : INFO : EPOCH 28 - PROGRESS: at 76.42% examples, 618320 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:33,537 : INFO : EPOCH 28: training on 2938062 raw words (1147813 effective words) took 1.9s, 602019 effective words/s\n",
      "2022-10-17 00:12:34,544 : INFO : EPOCH 29 - PROGRESS: at 77.39% examples, 627122 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:35,420 : INFO : EPOCH 29: training on 2938062 raw words (1147647 effective words) took 1.9s, 610506 effective words/s\n",
      "2022-10-17 00:12:36,428 : INFO : EPOCH 30 - PROGRESS: at 73.37% examples, 592148 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:37,357 : INFO : EPOCH 30: training on 2938062 raw words (1147567 effective words) took 1.9s, 593508 effective words/s\n",
      "2022-10-17 00:12:38,374 : INFO : EPOCH 31 - PROGRESS: at 72.30% examples, 578498 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:39,353 : INFO : EPOCH 31: training on 2938062 raw words (1147673 effective words) took 2.0s, 576053 effective words/s\n",
      "2022-10-17 00:12:40,375 : INFO : EPOCH 32 - PROGRESS: at 72.30% examples, 574767 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:41,345 : INFO : EPOCH 32: training on 2938062 raw words (1147895 effective words) took 2.0s, 577090 effective words/s\n",
      "2022-10-17 00:12:42,348 : INFO : EPOCH 33 - PROGRESS: at 74.49% examples, 603257 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:43,328 : INFO : EPOCH 33: training on 2938062 raw words (1147767 effective words) took 2.0s, 579756 effective words/s\n",
      "2022-10-17 00:12:44,336 : INFO : EPOCH 34 - PROGRESS: at 61.57% examples, 488845 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:45,401 : INFO : EPOCH 34 - PROGRESS: at 98.00% examples, 454873 words/s, in_qsize 2, out_qsize 0\n",
      "2022-10-17 00:12:45,764 : INFO : EPOCH 34: training on 2938062 raw words (1148180 effective words) took 2.4s, 471885 effective words/s\n",
      "2022-10-17 00:12:46,780 : INFO : EPOCH 35 - PROGRESS: at 47.52% examples, 374324 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:47,789 : INFO : EPOCH 35 - PROGRESS: at 96.98% examples, 406701 words/s, in_qsize 2, out_qsize 0\n",
      "2022-10-17 00:12:48,549 : INFO : EPOCH 35: training on 2938062 raw words (1147935 effective words) took 2.8s, 412831 effective words/s\n",
      "2022-10-17 00:12:49,573 : INFO : EPOCH 36 - PROGRESS: at 51.12% examples, 396684 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:50,589 : INFO : EPOCH 36 - PROGRESS: at 97.45% examples, 428429 words/s, in_qsize 0, out_qsize 1\n",
      "2022-10-17 00:12:51,266 : INFO : EPOCH 36: training on 2938062 raw words (1147919 effective words) took 2.7s, 422994 effective words/s\n",
      "2022-10-17 00:12:52,298 : INFO : EPOCH 37 - PROGRESS: at 41.55% examples, 330946 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:53,299 : INFO : EPOCH 37 - PROGRESS: at 97.60% examples, 446229 words/s, in_qsize 1, out_qsize 0\n",
      "2022-10-17 00:12:53,741 : INFO : EPOCH 37: training on 2938062 raw words (1147440 effective words) took 2.5s, 467121 effective words/s\n",
      "2022-10-17 00:12:54,745 : INFO : EPOCH 38 - PROGRESS: at 66.33% examples, 533883 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:55,782 : INFO : EPOCH 38 - PROGRESS: at 98.81% examples, 499218 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:56,086 : INFO : EPOCH 38: training on 2938062 raw words (1147307 effective words) took 2.3s, 490059 effective words/s\n",
      "2022-10-17 00:12:57,115 : INFO : EPOCH 39 - PROGRESS: at 32.03% examples, 253528 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:58,142 : INFO : EPOCH 39 - PROGRESS: at 65.33% examples, 257020 words/s, in_qsize 0, out_qsize 0\n",
      "2022-10-17 00:12:59,155 : INFO : EPOCH 39 - PROGRESS: at 97.50% examples, 291692 words/s, in_qsize 5, out_qsize 0\n",
      "2022-10-17 00:12:59,614 : INFO : EPOCH 39: training on 2938062 raw words (1147738 effective words) took 3.5s, 326320 effective words/s\n",
      "2022-10-17 00:12:59,614 : INFO : Doc2Vec lifecycle event {'msg': 'training on 117522480 raw words (45906810 effective words) took 84.5s, 543597 effective words/s', 'datetime': '2022-10-17T00:12:59.614723', 'gensim': '4.2.0', 'python': '3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:29:51) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "class files:\n",
    "    def __iter__(self):\n",
    "        self.list_of_files = list_of_files\n",
    "        self.counter = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.counter >= len(self.list_of_files):\n",
    "            raise StopIteration\n",
    "        \n",
    "        filename = self.list_of_files[self.counter]\n",
    "        with open(filename, encoding=\"mbcs\") as f:\n",
    "            content = f.read().split(\"\\n\")\n",
    "        self.counter += 1\n",
    "        return gensim.models.doc2vec.TaggedDocument(content, [self.counter-1])\n",
    "        \n",
    "    \n",
    "import gensim\n",
    "\n",
    "# model = Word2Vec(sentences=files(), vector_size=100, window=5, min_count=1, workers=4)\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=10, epochs=40)\n",
    "model.build_vocab(files())\n",
    "model.train(files(), total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca7469de-b4d2-425b-89df-8fcf48bc9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "train_corpus = list(files())\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e70effa7-780c-4f4a-969f-8e8b6a80a382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 815, 1: 243, 2: 73, 3: 59, 4: 58, 5: 30, 6: 28, 7: 27, 10: 18, 15: 17, 12: 16, 8: 16, 25: 15, 9: 14, 14: 14, 13: 13, 17: 10, 87: 10, 29: 9, 28: 9, 86: 9, 11: 9, 36: 9, 50: 9, 80: 9, 55: 9, 120: 8, 133: 8, 35: 8, 78: 8, 297: 8, 40: 8, 21: 8, 34: 8, 777: 7, 151: 7, 31: 7, 66: 7, 16: 7, 22: 7, 83: 7, 48: 7, 72: 7, 42: 7, 19: 6, 57: 6, 158: 6, 20: 6, 47: 6, 383: 6, 77: 6, 146: 6, 183: 6, 124: 6, 227: 6, 27: 6, 102: 6, 200: 6, 70: 6, 44: 6, 554: 6, 85: 6, 82: 6, 157: 5, 224: 5, 68: 5, 52: 5, 43: 5, 37: 5, 244: 5, 145: 5, 226: 5, 233: 5, 51: 5, 367: 5, 107: 5, 538: 5, 100: 5, 140: 5, 488: 5, 45: 5, 110: 5, 60: 5, 267: 5, 314: 5, 127: 5, 271: 5, 69: 5, 24: 5, 201: 5, 38: 5, 81: 5, 116: 5, 76: 5, 75: 5, 1024: 5, 287: 5, 26: 5, 187: 5, 98: 5, 309: 5, 63: 5, 280: 5, 23: 5, 239: 5, 154: 5, 732: 5, 137: 5, 191: 5, 176: 4, 326: 4, 94: 4, 64: 4, 167: 4, 74: 4, 171: 4, 33: 4, 649: 4, 117: 4, 407: 4, 466: 4, 90: 4, 152: 4, 193: 4, 119: 4, 401: 4, 41: 4, 437: 4, 136: 4, 198: 4, 112: 4, 135: 4, 61: 4, 118: 4, 161: 4, 175: 4, 472: 4, 126: 4, 138: 4, 184: 4, 56: 4, 400: 4, 96: 4, 231: 4, 1133: 4, 251: 4, 665: 4, 240: 4, 486: 4, 347: 4, 192: 4, 626: 4, 159: 4, 339: 4, 1441: 4, 150: 4, 1539: 4, 174: 4, 325: 4, 65: 4, 153: 4, 88: 4, 728: 4, 482: 4, 640: 4, 986: 4, 1103: 4, 163: 4, 330: 4, 344: 4, 208: 4, 709: 4, 108: 4, 131: 4, 30: 4, 875: 4, 147: 4, 334: 4, 1371: 4, 1498: 4, 194: 4, 387: 4, 546: 4, 825: 4, 874: 4, 291: 4, 106: 4, 349: 4, 760: 4, 797: 4, 252: 4, 464: 4, 168: 4, 272: 3, 160: 3, 262: 3, 394: 3, 215: 3, 551: 3, 218: 3, 459: 3, 229: 3, 123: 3, 449: 3, 589: 3, 348: 3, 73: 3, 210: 3, 93: 3, 710: 3, 499: 3, 101: 3, 316: 3, 744: 3, 374: 3, 1440: 3, 109: 3, 512: 3, 336: 3, 579: 3, 1775: 3, 217: 3, 641: 3, 1255: 3, 1312: 3, 1110: 3, 1646: 3, 1047: 3, 733: 3, 148: 3, 142: 3, 71: 3, 1302: 3, 763: 3, 813: 3, 247: 3, 634: 3, 756: 3, 1000: 3, 1327: 3, 46: 3, 597: 3, 1264: 3, 84: 3, 684: 3, 379: 3, 1005: 3, 932: 3, 537: 3, 125: 3, 318: 3, 1339: 3, 294: 3, 1224: 3, 670: 3, 79: 3, 721: 3, 188: 3, 757: 3, 722: 3, 1029: 3, 1649: 3, 95: 3, 1243: 3, 355: 3, 680: 3, 329: 3, 1341: 3, 186: 3, 1069: 3, 695: 3, 1027: 3, 802: 3, 357: 3, 1139: 3, 1437: 3, 225: 3, 59: 3, 1082: 3, 323: 3, 1738: 3, 190: 3, 846: 3, 1014: 3, 841: 3, 1229: 3, 1004: 3, 1510: 3, 32: 3, 264: 3, 1295: 3, 935: 3, 343: 3, 1311: 3, 1653: 3, 999: 3, 1038: 3, 1108: 3, 1506: 3, 698: 3, 288: 3, 268: 3, 172: 3, 179: 3, 1223: 3, 1508: 3, 480: 3, 380: 3, 529: 3, 303: 3, 1407: 3, 377: 3, 289: 3, 1025: 3, 1205: 3, 569: 3, 522: 3, 341: 3, 245: 3, 552: 3, 266: 3, 259: 3, 340: 3, 919: 3, 1066: 3, 319: 3, 223: 3, 501: 3, 134: 3, 365: 3, 1120: 3, 243: 3, 843: 3, 1638: 3, 1610: 3, 726: 3, 199: 3, 620: 3, 519: 3, 1201: 3, 177: 3, 406: 3, 564: 3, 1116: 3, 517: 3, 169: 3, 1388: 3, 415: 3, 295: 3, 104: 3, 1150: 3, 113: 3, 257: 3, 97: 3, 759: 3, 238: 3, 452: 3, 62: 3, 993: 3, 376: 3, 293: 3, 1480: 3, 405: 3, 735: 3, 650: 3, 573: 2, 265: 2, 260: 2, 388: 2, 381: 2, 429: 2, 54: 2, 822: 2, 426: 2, 599: 2, 185: 2, 1051: 2, 609: 2, 940: 2, 155: 2, 527: 2, 526: 2, 258: 2, 470: 2, 559: 2, 1360: 2, 428: 2, 417: 2, 431: 2, 446: 2, 279: 2, 335: 2, 574: 2, 162: 2, 905: 2, 921: 2, 1397: 2, 166: 2, 143: 2, 128: 2, 312: 2, 235: 2, 629: 2, 503: 2, 1268: 2, 1316: 2, 356: 2, 103: 2, 447: 2, 1378: 2, 18: 2, 1442: 2, 1385: 2, 324: 2, 914: 2, 263: 2, 1472: 2, 1735: 2, 1541: 2, 859: 2, 1124: 2, 604: 2, 917: 2, 1111: 2, 651: 2, 596: 2, 220: 2, 412: 2, 894: 2, 691: 2, 498: 2, 1445: 2, 1659: 2, 692: 2, 727: 2, 1191: 2, 1708: 2, 132: 2, 1218: 2, 1237: 2, 612: 2, 211: 2, 617: 2, 785: 2, 246: 2, 902: 2, 619: 2, 494: 2, 736: 2, 815: 2, 354: 2, 561: 2, 995: 2, 540: 2, 1564: 2, 1331: 2, 957: 2, 465: 2, 880: 2, 873: 2, 1053: 2, 219: 2, 924: 2, 3083: 2, 944: 2, 105: 2, 182: 2, 39: 2, 845: 2, 525: 2, 600: 2, 425: 2, 1018: 2, 1395: 2, 673: 2, 1089: 2, 858: 2, 375: 2, 419: 2, 320: 2, 451: 2, 351: 2, 502: 2, 1365: 2, 418: 2, 49: 2, 1569: 2, 1536: 2, 448: 2, 1715: 2, 764: 2, 1393: 2, 250: 2, 1282: 2, 839: 2, 903: 2, 1284: 2, 255: 2, 1271: 2, 1241: 2, 713: 2, 241: 2, 139: 2, 840: 2, 712: 2, 1418: 2, 590: 2, 1391: 2, 1293: 2, 1680: 2, 1704: 2, 1411: 2, 313: 2, 475: 2, 165: 2, 1574: 2, 89: 2, 528: 2, 632: 2, 1425: 2, 867: 2, 784: 2, 925: 2, 1240: 2, 364: 2, 181: 2, 856: 2, 1690: 2, 1165: 2, 701: 2, 1549: 2, 1328: 2, 1155: 2, 1650: 2, 489: 2, 463: 2, 315: 2, 787: 2, 337: 2, 1961: 2, 1612: 2, 1058: 2, 495: 2, 1466: 2, 762: 2, 129: 2, 747: 2, 1128: 2, 209: 2, 114: 2, 1122: 2, 1127: 2, 1652: 2, 514: 2, 674: 2, 58: 2, 681: 2, 443: 2, 1203: 2, 563: 2, 442: 2, 1596: 2, 311: 2, 249: 2, 1383: 2, 509: 2, 1045: 2, 342: 2, 616: 2, 410: 2, 878: 2, 479: 2, 1581: 2, 1457: 2, 1350: 2, 1351: 2, 823: 2, 308: 2, 614: 2, 1763: 2, 814: 2, 930: 2, 1104: 2, 553: 2, 1206: 2, 627: 2, 395: 2, 455: 2, 1028: 2, 1314: 2, 956: 2, 1020: 2, 1119: 2, 1353: 2, 835: 2, 1384: 2, 234: 2, 454: 2, 1086: 2, 416: 2, 53: 2, 1705: 2, 1373: 2, 1561: 2, 1617: 2, 456: 2, 1483: 2, 1960: 2, 1583: 2, 1334: 2, 1502: 2, 866: 2, 567: 2, 1067: 2, 1215: 2, 427: 2, 149: 2, 550: 2, 338: 2, 420: 2, 688: 2, 304: 2, 1524: 2, 1010: 2, 1036: 2, 1364: 2, 631: 2, 821: 2, 881: 2, 1644: 2, 575: 2, 1504: 2, 738: 2, 731: 2, 1176: 2, 1212: 2, 964: 2, 1520: 2, 1500: 2, 1387: 2, 1490: 2, 196: 2, 1689: 2, 1672: 2, 432: 2, 396: 2, 1514: 2, 277: 2, 275: 2, 828: 2, 868: 2, 706: 2, 402: 2, 638: 2, 236: 2, 685: 2, 677: 2, 654: 2, 1062: 2, 1102: 2, 643: 2, 1595: 2, 1049: 2, 1377: 2, 978: 2, 487: 2, 290: 2, 435: 2, 206: 2, 510: 2, 1621: 2, 719: 2, 1064: 2, 1608: 2, 195: 2, 458: 2, 371: 2, 715: 2, 1262: 2, 122: 2, 516: 2, 718: 2, 676: 2, 1279: 2, 581: 2, 1068: 2, 1592: 2, 1374: 2, 983: 2, 1428: 2, 397: 2, 1195: 2, 214: 2, 1528: 2, 1263: 2, 1050: 2, 1131: 2, 1465: 1, 1003: 1, 792: 1, 982: 1, 786: 1, 500: 1, 232: 1, 121: 1, 491: 1, 164: 1, 565: 1, 485: 1, 602: 1, 197: 1, 369: 1, 430: 1, 970: 1, 661: 1, 237: 1, 960: 1, 1324: 1, 865: 1, 608: 1, 1071: 1, 671: 1, 1163: 1, 1479: 1, 746: 1, 473: 1, 973: 1, 1713: 1, 1588: 1, 928: 1, 1272: 1, 1467: 1, 1160: 1, 704: 1, 1178: 1, 683: 1, 378: 1, 507: 1, 1292: 1, 675: 1, 282: 1, 987: 1, 409: 1, 1766: 1, 1618: 1, 647: 1, 1804: 1, 906: 1, 1362: 1, 1199: 1, 477: 1, 1631: 1, 1077: 1, 652: 1, 144: 1, 1074: 1, 1044: 1, 1423: 1, 937: 1, 1013: 1, 1550: 1, 1911: 1, 598: 1, 1501: 1, 1381: 1, 560: 1, 1048: 1, 1579: 1, 1202: 1, 833: 1, 1226: 1, 1012: 1, 1556: 1, 301: 1, 1692: 1, 946: 1, 893: 1, 1294: 1, 1430: 1, 450: 1, 284: 1, 773: 1, 3357: 1, 3071: 1, 1563: 1, 1910: 1, 1651: 1, 413: 1, 2310: 1, 1567: 1, 2059: 1, 1743: 1, 1092: 1, 1359: 1, 1043: 1, 915: 1, 630: 1, 2151: 1, 1641: 1, 2914: 1, 1482: 1, 576: 1, 2324: 1, 1254: 1, 1806: 1, 532: 1, 1458: 1, 2230: 1, 588: 1, 1543: 1, 1533: 1, 1571: 1, 1305: 1, 1269: 1, 659: 1, 1682: 1, 918: 1, 566: 1, 1602: 1, 2991: 1, 345: 1, 989: 1, 1233: 1, 778: 1, 1182: 1, 804: 1, 130: 1, 1655: 1, 1786: 1, 768: 1, 829: 1, 3097: 1, 492: 1, 370: 1, 384: 1, 809: 1, 908: 1, 1734: 1, 1454: 1, 1157: 1, 1416: 1, 1063: 1, 1125: 1, 392: 1, 67: 1, 511: 1, 1037: 1, 1681: 1, 985: 1, 1492: 1, 359: 1, 189: 1, 740: 1, 864: 1, 1363: 1, 1755: 1, 2304: 1, 1079: 1, 1299: 1, 606: 1, 1546: 1, 404: 1, 686: 1, 971: 1, 693: 1, 591: 1, 934: 1, 702: 1, 1770: 1, 1366: 1, 1390: 1, 462: 1, 1121: 1, 1075: 1, 1455: 1, 1097: 1, 806: 1, 1803: 1, 3146: 1, 1148: 1, 170: 1, 202: 1, 1039: 1, 767: 1, 1167: 1, 1303: 1, 1509: 1, 1105: 1, 1174: 1, 1238: 1, 1046: 1, 2643: 1, 1011: 1, 1849: 1, 1289: 1, 1794: 1, 3201: 1, 1016: 1, 1230: 1, 1361: 1, 1217: 1, 949: 1, 254: 1, 399: 1, 1719: 1, 952: 1, 3941: 1, 1406: 1, 1629: 1, 363: 1, 644: 1, 696: 1, 642: 1, 765: 1, 1727: 1, 1625: 1, 1211: 1, 1275: 1, 1147: 1, 1456: 1, 515: 1, 1059: 1, 1686: 1, 1447: 1, 178: 1, 969: 1, 2780: 1, 1132: 1, 4099: 1, 1300: 1, 1347: 1, 306: 1, 1207: 1, 1640: 1, 689: 1, 504: 1, 1382: 1, 898: 1, 1310: 1, 793: 1, 508: 1, 1040: 1, 1396: 1, 1503: 1, 1304: 1, 967: 1, 286: 1, 1283: 1, 585: 1, 1094: 1, 3553: 1, 1741: 1, 478: 1, 1519: 1, 1478: 1, 3124: 1, 2882: 1, 1278: 1, 837: 1, 439: 1, 788: 1, 1887: 1, 847: 1, 1710: 1, 1687: 1, 1298: 1, 819: 1, 1072: 1, 4123: 1, 1151: 1, 1410: 1, 1446: 1, 3719: 1, 587: 1, 1825: 1, 1530: 1, 3512: 1, 1725: 1, 850: 1, 1732: 1, 1493: 1, 1417: 1, 1438: 1, 562: 1, 2606: 1, 2263: 1, 1468: 1, 1717: 1, 1273: 1, 1419: 1, 1798: 1, 3544: 1, 1523: 1, 385: 1, 1716: 1, 3057: 1, 1321: 1, 694: 1, 2107: 1, 972: 1, 1683: 1, 1286: 1, 1379: 1, 1623: 1, 660: 1, 2268: 1, 658: 1, 1056: 1, 1408: 1, 1671: 1, 761: 1, 1405: 1, 1673: 1, 2510: 1, 1527: 1, 1893: 1, 496: 1, 1413: 1, 1177: 1, 1526: 1, 1168: 1, 679: 1, 469: 1, 2923: 1, 1724: 1, 1429: 1, 1106: 1, 203: 1, 1676: 1, 1469: 1, 1145: 1, 3120: 1, 682: 1, 3382: 1, 1434: 1, 981: 1, 974: 1, 3662: 1, 362: 1, 1134: 1, 794: 1, 545: 1, 270: 1, 445: 1, 3141: 1, 959: 1, 1999: 1, 299: 1, 1376: 1, 1153: 1, 779: 1, 1197: 1, 1175: 1, 1685: 1, 771: 1, 1788: 1, 594: 1, 368: 1, 1968: 1, 1221: 1, 1185: 1, 700: 1, 3187: 1, 1453: 1, 1210: 1, 1448: 1, 648: 1, 1096: 1, 1189: 1, 1647: 1, 1964: 1, 2162: 1, 1807: 1, 1487: 1, 1420: 1, 1348: 1, 791: 1, 1216: 1, 690: 1, 298: 1, 1532: 1, 2450: 1, 549: 1, 1691: 1, 1260: 1, 1511: 1, 1529: 1, 92: 1, 1115: 1, 1054: 1, 1476: 1, 714: 1, 758: 1, 1945: 1, 3074: 1, 803: 1, 1517: 1, 945: 1, 1065: 1, 752: 1, 1232: 1, 889: 1, 1161: 1, 851: 1, 276: 1, 577: 1, 699: 1, 1706: 1, 543: 1, 1159: 1, 1015: 1, 1288: 1, 711: 1, 729: 1, 386: 1, 1170: 1, 283: 1, 372: 1, 774: 1, 156: 1, 1113: 1, 261: 1, 904: 1, 1666: 1, 1181: 1, 421: 1, 321: 1, 782: 1, 820: 1, 789: 1, 876: 1, 1609: 1, 2756: 1, 742: 1, 592: 1, 611: 1, 743: 1, 997: 1, 471: 1, 141: 1, 605: 1, 300: 1, 1675: 1, 1266: 1, 327: 1, 621: 1, 628: 1, 939: 1, 975: 1, 739: 1, 720: 1, 4108: 1, 795: 1, 572: 1, 467: 1, 911: 1, 212: 1, 725: 1, 1720: 1, 433: 1, 3308: 1, 776: 1, 1076: 1, 1026: 1, 1768: 1, 1276: 1, 796: 1, 672: 1, 753: 1, 228: 1, 3699: 1, 536: 1, 938: 1, 1904: 1, 3084: 1, 1432: 1, 253: 1, 1565: 1, 204: 1, 657: 1, 533: 1, 992: 1, 618: 1, 2682: 1, 926: 1, 1751: 1, 1986: 1, 966: 1, 896: 1, 1035: 1, 923: 1, 580: 1, 748: 1, 615: 1, 1450: 1, 292: 1, 221: 1, 826: 1, 838: 1, 366: 1, 799: 1, 811: 1, 438: 1, 216: 1, 897: 1, 1861: 1, 317: 1, 1007: 1, 669: 1, 663: 1, 414: 1, 770: 1, 391: 1, 1370: 1, 1812: 1, 891: 1, 724: 1, 285: 1, 2300: 1, 1372: 1, 1494: 1, 610: 1, 613: 1, 3023: 1, 884: 1, 708: 1, 1166: 1, 909: 1, 390: 1, 697: 1, 558: 1, 91: 1, 2243: 1, 207: 1, 1905: 1, 1787: 1, 1136: 1, 3092: 1, 111: 1, 1252: 1, 1414: 1, 1831: 1, 1088: 1, 2500: 1, 1349: 1, 931: 1, 3486: 1, 1424: 1, 1712: 1, 1231: 1, 3007: 1, 1042: 1, 955: 1, 977: 1, 4192: 1, 3204: 1, 1402: 1, 586: 1, 1281: 1, 1398: 1, 1605: 1, 988: 1, 1357: 1, 1870: 1, 1246: 1, 1006: 1, 1449: 1, 3126: 1, 1473: 1, 2618: 1, 901: 1, 1484: 1, 436: 1, 555: 1, 1857: 1, 273: 1, 3109: 1, 2040: 1, 1459: 1, 863: 1, 1162: 1, 1711: 1, 1840: 1, 886: 1, 1325: 1, 4058: 1, 869: 1, 1662: 1, 1309: 1, 3068: 1, 861: 1, 1158: 1, 1767: 1, 808: 1, 281: 1, 1903: 1, 1769: 1, 305: 1, 4093: 1, 3227: 1, 1346: 1, 1344: 1, 1235: 1, 1354: 1, 1660: 1, 1326: 1, 539: 1, 2995: 1, 1140: 1, 1095: 1, 1329: 1, 1613: 1, 1635: 1, 393: 1, 422: 1, 1008: 1, 790: 1, 1394: 1, 544: 1, 1731: 1, 1322: 1, 1582: 1, 3727: 1, 1678: 1, 1736: 1, 2638: 1, 2220: 1, 1547: 1, 2208: 1, 1977: 1, 1744: 1, 1404: 1, 1562: 1, 780: 1, 3321: 1, 1200: 1, 3070: 1, 1974: 1, 444: 1, 1632: 1, 963: 1, 636: 1, 3642: 1, 2559: 1, 307: 1, 408: 1, 3047: 1, 1707: 1, 524: 1, 1274: 1, 892: 1, 1594: 1, 1186: 1, 1859: 1, 1183: 1, 920: 1, 296: 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3387"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)\n",
    "\n",
    "sum([v for k, v in counter.items() if k != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef3d10-aff7-413b-8a49-6ef10240008c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
